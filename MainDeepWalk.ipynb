{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 4998\n",
      "Number of walks: 399840\n",
      "Data size (walks*length): 15993600\n",
      "Walking...\n",
      "Training...\n"
     ]
    }
   ],
   "source": [
    "#! /usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "from io import open\n",
    "from argparse import ArgumentParser, FileType, ArgumentDefaultsHelpFormatter\n",
    "from collections import Counter\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import logging\n",
    "\n",
    "import graph\n",
    "from skipgram import Skipgram\n",
    "import walks as serialized_walks\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from six import text_type as unicode\n",
    "from six import iteritems\n",
    "from six.moves import range\n",
    "\n",
    "import psutil\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "p = psutil.Process(os.getpid())\n",
    "try:\n",
    "    p.set_cpu_affinity(list(range(cpu_count())))\n",
    "except AttributeError:\n",
    "    try:\n",
    "        p.cpu_affinity(list(range(cpu_count())))\n",
    "    except AttributeError:\n",
    "        pass\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "LOGFORMAT = \"%(asctime).19s %(levelname)s %(filename)s: %(lineno)s %(message)s\"\n",
    "\n",
    "\n",
    "def debug(type_, value, tb):\n",
    "    if hasattr(sys, 'ps1') or not sys.stderr.isatty():\n",
    "        sys.__excepthook__(type_, value, tb)\n",
    "    else:\n",
    "        import traceback\n",
    "        import pdb\n",
    "        traceback.print_exception(type_, value, tb)\n",
    "        print(u\"\\n\")\n",
    "        pdb.pm()\n",
    "\n",
    "\n",
    "def process():\n",
    "\n",
    "    if format == \"adjlist\":\n",
    "        G = graph.load_adjacencylist(input, undirected=undirected)\n",
    "    elif format == \"edgelist\":\n",
    "        G = graph.load_edgelist(input, undirected=undirected)\n",
    "    elif format == \"mat\":\n",
    "        G = graph.load_matfile(input, variable_name=matfile_variable_name, undirected=undirected)\n",
    "    else:\n",
    "        raise Exception(\"Unknown file format: '%s'.  Valid formats: 'adjlist', 'edgelist', 'mat'\" % format)\n",
    "\n",
    "    print(\"Number of nodes: {}\".format(len(G.nodes())))\n",
    "\n",
    "    num_walks = len(G.nodes()) * number_walks\n",
    "\n",
    "    print(\"Number of walks: {}\".format(num_walks))\n",
    "\n",
    "    data_size = num_walks * walk_length\n",
    "\n",
    "    print(\"Data size (walks*length): {}\".format(data_size))\n",
    "\n",
    "    if data_size < max_memory_data_size:\n",
    "        print(\"Walking...\")\n",
    "        walks = graph.build_deepwalk_corpus(G, num_paths=number_walks,\n",
    "                                        path_length=walk_length, alpha=0, rand=random.Random(seed))\n",
    "        print(\"Training...\")\n",
    "        model = Word2Vec(walks, size=representation_size, window=window_size, min_count=0, sg=1, hs=1, workers=workers)\n",
    "    else:\n",
    "        print(\"Data size {} is larger than limit (max-memory-data-size: {}).  Dumping walks to disk.\".format(data_size, max_memory_data_size))\n",
    "        print(\"Walking...\")\n",
    "\n",
    "        walks_filebase = output + \".walks\"\n",
    "        walk_files = serialized_walks.write_walks_to_disk(G, walks_filebase, num_paths=number_walks,\n",
    "                                         path_length=walk_length, alpha=0, rand=random.Random(seed),\n",
    "                                         num_workers=workers)\n",
    "\n",
    "        print(\"Counting vertex frequency...\")\n",
    "        if not vertex_freq_degree:\n",
    "            vertex_counts = serialized_walks.count_textfiles(walk_files, workers)\n",
    "        else:\n",
    "            # use degree distribution for frequency in tree\n",
    "            vertex_counts = G.degree(nodes=G.iterkeys())\n",
    "\n",
    "        print(\"Training...\")\n",
    "        walks_corpus = serialized_walks.WalksCorpus(walk_files)\n",
    "        model = Skipgram(sentences=walks_corpus, vocabulary_counts=vertex_counts, size=representation_size, window=window_size, min_count=0, trim_rule=None, workers=workers)\n",
    "\n",
    "    model.wv.save_word2vec_format(output)\n",
    "\n",
    "\n",
    "# Start the main function here.\n",
    "#parser = ArgumentParser(\"deepwalk\", formatter_class=ArgumentDefaultsHelpFormatter, conflict_handler='resolve')\n",
    "\n",
    "# Drop a debugger if an exception is raised.\n",
    "# parser.add_argument(\"--debug\", dest=\"debug\", action='store_true', default=False, help=\"drop a debugger if an exception is raised.\")\n",
    "debug = 'False'\n",
    "\n",
    "# File format of input file.\n",
    "format = 'adjlist'\n",
    "\n",
    "# Input graph file.\n",
    "input = 'Adjlist_FR.tsv'\n",
    "\n",
    "# Log verbosity level.\n",
    "# parser.add_argument(\"-l\", \"--log\", dest=\"log\", default=\"INFO\", help=\"log verbosity level\")\n",
    "log = \"INFO\"\n",
    "\n",
    "# Variable name of adjacency matrix inside a .mat file.\n",
    "matfile_variable_name = 'network'\n",
    "\n",
    "# Size to start dumping walks to disk, instead of keeping them in memory.\n",
    "max_memory_data_size = 1000000000\n",
    "\n",
    "# Number of random walks to start at each node.\n",
    "number_walks = 80\n",
    "\n",
    "# Output representation file.\n",
    "output = 'success.txt'\n",
    "\n",
    "# Number of latent dimensions to learn for each node.\n",
    "representation_size = 128\n",
    "\n",
    "# Seed for random walk generator.\n",
    "seed = 0\n",
    "\n",
    "# Treat graph as undirected.\n",
    "undirected = True\n",
    "\n",
    "# Use vertex degree to estimate the frequency of nodes in the random walks. \n",
    "# This option is faster than calculating the vocabulary.\n",
    "vertex_freq_degree = False\n",
    "\n",
    "# Length of the random walk started at each node\n",
    "walk_length = 40\n",
    "\n",
    "# Window size of skipgram model.\n",
    "window_size = 10\n",
    "\n",
    "# Number of parallel processes\n",
    "workers=1 \n",
    "\n",
    "numeric_level = getattr(logging, log.upper(), None)\n",
    "logging.basicConfig(format=LOGFORMAT)\n",
    "logger.setLevel(numeric_level)\n",
    "\n",
    "if debug:\n",
    "    sys.excepthook = debug\n",
    "\n",
    "process()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
